#include <iostream>
#include <climits>
#include <cmath>
#include <vector>
#include <cstring>
#include <bits/stdc++.h> 
#include <boost/algorithm/string.hpp> 
using namespace std;
vector<vector<float>> processed_input(vector<vector<float>> input,int kernel_size){

    vector<vector<float>> output
    for(int i=0;i<kernal_size;i++){
        for(int j=1;j<=(input.size()-kernal_size);j++){
            for(int k=1;k<=(input.size()-kernal_size);k++){
                if(i==0){
                    vector<float> v;
                    output.push_back(v);
                }
                for(int x=0;x<kernal_size;x++){
                    output[j*k-1].push_back(input[i+j-1][k+x-1]);
                }
            }

        }
    }
    return output;

} 
vector<vector<float>> processed_kernel(vector<vector<float>> kernel){

    vector<vector<float>> output;
    for(int i=0;i<kernal.size();i++){
        vector<float> v;
        output.push_back(v);
        for(int j=0;j<kernal[i].size();i++){
            output[i*3+j].push_back(input[i][j]);
        }
     }
    return output;
}

vector<vector<float>> matrix_mult(vector<vector<float>> input,vector<vector<<float> kernel){
    vector<vector<float>> output;
    float sum=0;
    for(int i=0;i<input.size();i++){
    	vector<float> v;
		output.push_back(v);
        for(int j=0;j<kernel[0].size();j++){
            sum=0;
            for(int k=0;k<kernel.size();k++){
                sum+=input[i][k]*kernel[k][j];
            }
            output[i].push_back(sum);
        }
    }
    return output;
}
    
vector<vector<float>> inverse_input(vector<vector<float>> input){
    vector<vector<float>> output;
    int i= (int)sqrt(input.size());

    for(int k=1;k<=i;k++){
        vector<float> v;
        output.push_back(v);
        for(int j=1;j<=i;j++){
            output[k-1].push_back(input[k*j-1][0]);
        }
    }
    return output;
}

vector<vector<float>> convolution_withoutpadding(vector<vector<float>> input,vector<vector<float>> kernel){
             vector<vector<float>> output;
             for(int i=0;i<input.size()-kernel.size()+1;i++){
             	vector<float> v;
		        output.push_back(v);
             	for(int j=0;j<input.size()-kernel.size()+1;j++){
             		float sum=0;
             		for(int u=0;u<kernel.size();u++){
             	       for(int v=0;v<kernel.size();v++){
                            sum+=(input[i+u][j+v]*kernel[u][v]);
             	       }   
             		}
             	}
             	  output[i].push_back(sum);	
             }
  return output;
}

vector<vector<float>> convolution_withoutpadding_matrixmult(vector<vector<float>> input,vector<vector<float>> kernel){

      return inverse_input(matrix_mult(processed_input(input,kernel.size()),processed_kernel(kernel)));
}

vector<vector<float>> padding(float padsize,vector<vector<float>> input){
	vector<vector<float> output;
	for(int i=0;i<input.size()+2*padsize;i++){
		  vector<float> v;
		  output.push_back(v);
        for(int j=0;j<input.size()+2*padsize;j++){
        	if(i<padsize||i>=input.size()+padsize||j<padsize||j>=input.size()+padsize)
             output.push_back(0.0);
            else
             output.push_back(input[i-padsize][j-padsize]); 	
        }
	}
}

vector<vector<float>> convolution_withpadding(float padsize,vector<vector<float>> input,vector<vector<float>> kernel){
      
      return convolution_withoutpadding(padding(padsize,input),kernel);
}

vector<vector<float>> convolution_withpadding_matrixmult(float padsize,vector<vector<float>> input,vector<vector<float>> kernel){

      return convolution_withoutpadding_matrixmult(padding(padsize,input),kernel);
}

vector<vector<float>> relu_activation(vector<vector<float>> input){
    for(int i=0;i<input.size();i++){
     	for(int j=0;j<input[i].size();i++){
     		input[i][j]=max(0,input[i][j]);
     	}
     }
    return input;
}

vector<vector<float>> tanh_activation(vector<vector<float>> input){
    for(int i=0;i<input.size();i++){
     	for(int j=0;j<input[i].size();i++){
     		input[i][j]=tanh(input[i][j]);
     	}
     }
   return input;   
}

// acts as a hidden layer in neural network by reducing the amount of data and taking relevant data by taking max of 2*2 sliding window
vector<vector<float>> max_pooling(vector<vector<float>> input){
    if(input.size()%2==1){
    	vector<float> extra;
    	for(int i=0;i<input.size();i++){
    		extra.push_back(0);
    	}
        input.push_back(extra);
        for(int i=0;i<input.size();i++){
        	input[i].push_back(0);
        }
    }
    vector<vector<float>> output;
    for(int i=0;i<input.size()/2;i++){
    	vector<float> v;
    	output.push_back(v);
    	for(int j=0;j<input.size()/2;j++){
    		output[i].push_back(max(input[2*i][2*j],max(input[2*i+1][2*j],max(input[2*i+1][2*j+1],input[2*i][2*j+1]))));
    	}
    }
    return output;
}

// acts as a hidden layer in neural network by reducing the amount of data and taking relevant data by taking average of 2*2 sliding window
vector<vector<float>> average_pooling(vector<vector<float>> input){
    if(input.size()%2==1){
    	vector<float> extra;
    for(int i=0;i<input.size();i++){
    		extra.push_back(0);
    	}
        input.push_back(extra);
    for(int i=0;i<input.size();i++){
        	input[i].push_back(0);
        }
    }
    vector<vector<float>> output;
    for(int i=0;i<input.size()/2;i++){
    	vector<float> v;
    	output.push_back(v);
    for(int j=0;j<input.size()/2;j++){
    		output[i].push_back((input[2*i][2*j]+input[2*i+1][2*j]+input[2*i+1][2*j+1]+input[2*i][2*j+1])/4);
    	}
    }
  return output;  
}
// maps the vector to [0,1] hence giving a measure of probability
vector<float> softmax(vector<float> input){
	float sum=0;
	vector<float> ouptut;
    for(int j=0;j<input.size();i++){
     		sum+=exp(input[j]);
     	}
    for(int j=0;j<input.size();i++){
     		output.push_back(exp(input[j])/sum);
     	}
    return output;
}
// maps the vector to [0,1] hence giving a measure of probability
vector<float> sigmoid(vector<float> input){
	vector<float> output;
	for(int j=0;j<input[i].size();i++){
     		output.push_back(1/(1+exp(-1*input[i])));
     	}
    return output; 	
}

int main(){
    string s;
     do{
          getline(cin,s);
          vector<string> result;
          split(result,s," ");
          if(result[0]=="convolution"){
              ifstream file1;
              file1.open(result[1]);
              int size1 = stoi(result[2]);
              vector<vector<float> input;
              for(int i=0;i<size1;i++){
              	for(int j=0;j<size1;j++){
              		if(i==0){
              		vector<float> v;
                    input.push_back(v);
                    }
                    file1>>x;
                    input[j].push_back(x);
              	}
              }
              ifstream file2;
              file2.open(result[3]);
              int size2 = stoi(result[4]);
              vector<vector<float>> kernel;

              for(int i=0;i<size2;i++){
              	for(int j=0;j<size2;j++){
              		if(i==0){
              		vector<float> v;
                    kernel.push_back(v);
                    }
                    file2>>x;
                    kernel[j].push_back(x);
              	}
              }
              display(convolution_withoutpadding(input,kernel));
          }
          else if(result[0]=="convolution_withpadding"){

          }
          else if(resullt[0]=="convolution_matrixmult"){

          }
          else if(result[0]=="convolution_withpadding_matrixmult"){

          }
          else if(result[0]=="softmax"){

          }
          else if(result[0]=="sigmoid"){
          	
          }
          else if(result[0]=="max_pooling"){

          }
          else if(result[0]=="average_pooling"){
          	
          }
          else if(result[0]=="relu_activation"){

          }
          else if(result[0]=="tanh_activation"){

          }
          

     }
     while(s!="\0");
    
}
